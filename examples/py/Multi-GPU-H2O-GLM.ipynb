{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# H2O.ai GPU Edition Machine Learning $-$ Multi-GPU GLM Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### In this demo, we will train 4000 regularized linear regression models (aka, Generalized Linear Models / GLMs) on the U.S. Census dataset, with the goal to predict the income of a person, given approximately 10000 features (such as age, occupation, zip code, etc.)\n",
    "\n",
    "### The dataset is about 2GB in memory (50k rows, 10k cols, single-precision floating-point values), so it fits onto the GPU memory.\n",
    "\n",
    "### By using multiple GPUs, we are able to speed up this process significantly, and can train about 40 models per second (on a DGX-1 with 8 GPUs) vs 1 model per second on dual-Xeon server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## First time only: Install dependencies\n",
    "#!pip install https://s3.amazonaws.com/h2o-beta-release/goai/h2oaiglm-0.0.2-py2.py3-none-any.whl\n",
    "#!pip install pandas seaborn psutil feather_format\n",
    "#!pip install -e \"git+https://github.com/fbcotter/py3nvml#egg=py3nvml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import feather\n",
    "import h2oaiglm as h2oaiglm\n",
    "from os.path import expanduser\n",
    "import psutil\n",
    "import subprocess\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from py3nvml.py3nvml import *\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "sns.set_style(\"whitegrid\")\n",
    "maxNGPUS = int(subprocess.check_output(\"nvidia-smi -L | wc -l\", shell=True))\n",
    "print(\"\\nNumber of GPUS:\", maxNGPUS)\n",
    "\n",
    "nvmlInit()\n",
    "deviceCount = nvmlDeviceGetCount()\n",
    "for i in range(deviceCount):\n",
    "    handle = nvmlDeviceGetHandleByIndex(i)\n",
    "    print(\"Device {}: {}\".format(i, nvmlDeviceGetName(handle)))\n",
    "print (\"Driver Version:\", nvmlSystemGetDriverVersion())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Import Data Frame and create raw X and y arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run: cd ~/h2oai-prototypes/ ; gunzip ipums.csv.gz ; R -f ipums_feather.R ; rm -rf ipums.csv ; git checkout ipums.csv.gz\n",
    "t0 = time.time()\n",
    "home = str(expanduser(\"~\"))\n",
    "filepostfix=\"/h2oai-prototypes/glm-bench/ipums.feather\"\n",
    "df = feather.read_dataframe(home+filepostfix)\n",
    "t1 = time.time()\n",
    "print(\"Time to read data via feather: %r\" % (t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## We predict the last column \"INCEARN\" - Income earned\n",
    "target = df.columns[-1]\n",
    "cols = [c for c in df.columns if c != target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df[target].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = np.array(df.ix[:,cols], order='f').astype('float32')\n",
    "y = np.array(df[target].values, dtype='float32')\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Split the dataset into Training (80%) and Validation (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "intercept = 1\n",
    "validFraction=0.2\n",
    "standardize = 0\n",
    "lambda_min_ratio = 1e-7\n",
    "\n",
    "if standardize:\n",
    "    print (\"implement standardization transformer\")\n",
    "    exit()\n",
    "\n",
    "# Setup Train/validation Set Split\n",
    "morig = X.shape[0]\n",
    "norig = X.shape[1]\n",
    "fortran = X.flags.f_contiguous\n",
    "print(\"fortran order=%d\" % (fortran))\n",
    "print(\"Full data rows=%d cols=%d\" % (morig,norig))\n",
    "\n",
    "# Do train/valid split\n",
    "HO=int(validFraction*morig)\n",
    "H=morig-HO\n",
    "print(\"Training  rows=%d\" % (H))\n",
    "print(\"Vaidation rows=%d\" % (HO))\n",
    "trainX = np.copy(X[0:H,:])\n",
    "trainY = np.copy(y[0:H])\n",
    "validX = np.copy(X[H:-1,:])\n",
    "validY = np.copy(y[H:-1])\n",
    "trainW = np.copy(trainY)*0.0 + 1.0 # constant unity weight\n",
    "\n",
    "mTrain = trainX.shape[0]\n",
    "mvalid = validX.shape[0]\n",
    "\n",
    "if intercept==1:\n",
    "    trainX = np.hstack([trainX, np.ones((trainX.shape[0],1),dtype=trainX.dtype)])\n",
    "    validX = np.hstack([validX, np.ones((validX.shape[0],1),dtype=validX.dtype)])\n",
    "    n = trainX.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Define some helper methods for plotting and running the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def new_alpha(row_fold):\n",
    "    if row_fold == 0:\n",
    "        return -0.025\n",
    "    elif row_fold == 1:\n",
    "        return -0.05\n",
    "    elif row_fold == 3:\n",
    "        return 0.025\n",
    "    elif row_fold == 4:\n",
    "        return 0.05\n",
    "    else: return 0\n",
    "\n",
    "def plot_cpu_perf(axis, cpu_labels, cpu_snapshot):\n",
    "    axis.cla()\n",
    "    axis.grid(False)\n",
    "    axis.set_ylim([0,100])\n",
    "    axis.set_ylabel('Percent', labelpad=2, fontsize = 14)\n",
    "    axis.bar(cpu_labels, cpu_snapshot, color='dodgerblue')\n",
    "    axis.set_title('CPU Utilization', fontsize = 16)\n",
    "    \n",
    "def plot_gpu_perf(axis, gpu_labels, gpu_snapshot):\n",
    "    axis.cla()\n",
    "    axis.grid(False)\n",
    "    axis.set_ylim([0,100])\n",
    "    axis.set_xticks(gpu_labels)\n",
    "    axis.set_ylabel('Percent', labelpad=2, fontsize = 14)\n",
    "    axis.bar(gpu_labels, gpu_snapshot, width =0.5, color = 'limegreen')\n",
    "    axis.set_title('GPU Utilization', fontsize = 16)\n",
    "    \n",
    "def plot_glm_results(axis, results, best_rmse, cb):\n",
    "    axis.cla()\n",
    "    axis.set_xscale('log')\n",
    "    axis.set_xlim([1e2, 1e9])\n",
    "    axis.set_ylim([-0.12, 1.12])\n",
    "    axis.set_yticks([x/7. for x in range(0,8)])\n",
    "    axis.set_ylabel('Parameter 1:  '+r'$\\alpha$', fontsize = 16)\n",
    "    axis.set_xlabel('Parameter 2:  '+r'$\\lambda$', fontsize = 16)\n",
    "    num_models = min(4000,int(4000*results.shape[0]/2570))\n",
    "    axis.set_title('Elastic Net Models Trained and Evaluated: ' + str(num_models), fontsize = 16)\n",
    "\n",
    "    try:\n",
    "        cm = ListedColormap(sns.color_palette(\"RdYlGn\", 10).as_hex())\n",
    "        cf = axis.scatter(results['lambda'], results['alpha_prime'], c=results['rel_acc'], \n",
    "                    cmap=cm, vmin=0, vmax=1)\n",
    "        axis.plot(best_rmse['lambda'],best_rmse['alpha_prime'], 'o',\n",
    "            ms=15, mec='k', mfc='none', mew=2)\n",
    "\n",
    "        if not cb:\n",
    "            cb = pl.colorbar(cf, ax=axis)\n",
    "            cb.set_label('Relative  Validation  Accuracy', rotation=270, \n",
    "                         labelpad=18, fontsize = 16)   \n",
    "        cb.update_normal(cf)\n",
    "    except:\n",
    "        #print(\"plot_glm_results exception -- no frame\")\n",
    "        pass\n",
    "    \n",
    "def RunAnimation(arg):\n",
    "    deviceCount = arg\n",
    "    file = os.getcwd() + \"/rmse.txt\"\n",
    "    fig = pl.figure(figsize = (9,9))\n",
    "    pl.rcParams['xtick.labelsize'] = 14\n",
    "    pl.rcParams['ytick.labelsize'] = 14\n",
    "    gs = gridspec.GridSpec(3, 2, wspace=0.3, hspace=0.4)\n",
    "    ax1 = pl.subplot(gs[0,-2])\n",
    "    ax2 = pl.subplot(gs[0,1])\n",
    "    ax3 = pl.subplot(gs[1:,:])\n",
    "    fig.suptitle('H2O.ai Machine Learning $-$ Generalized Linear Modeling', size=18)\n",
    "\n",
    "    pl.gcf().subplots_adjust(bottom=0.2)\n",
    "\n",
    "    cb = False\n",
    "    os.system(\"mkdir -p images\")\n",
    "    i=0\n",
    "    while(True):\n",
    "        try:\n",
    "            #cpu\n",
    "            snapshot = psutil.cpu_percent(percpu=True)\n",
    "            cpu_labels = range(1,len(snapshot)+1)\n",
    "            plot_cpu_perf(ax1, cpu_labels, snapshot)\n",
    "    \n",
    "            #gpu\n",
    "            gpu_snapshot = []\n",
    "            gpu_labels = list(range(1,deviceCount+1))\n",
    "            for j in range(deviceCount):\n",
    "                handle = nvmlDeviceGetHandleByIndex(j)\n",
    "                util = nvmlDeviceGetUtilizationRates(handle)\n",
    "                gpu_snapshot.append(util.gpu)\n",
    "            gpu_snapshot = gpu_snapshot   \n",
    "            plot_gpu_perf(ax2, gpu_labels, gpu_snapshot)\n",
    "    \n",
    "            res = pd.read_csv(file, sep=\"\\s+\",header=None,names=['time','pass','fold','a','i','alpha','lambda','trainrmse','ivalidrmse','validrmse'])\n",
    "            \n",
    "            res['rel_acc'] = ((42665- res['validrmse'])/(42665-31000))\n",
    "            res['alpha_prime'] = res['alpha'] + res['fold'].apply(lambda x: new_alpha(x))\n",
    "\n",
    "            best = res.ix[res['rel_acc']==np.max(res['rel_acc']),:]\n",
    "            plot_glm_results(ax3, res, best.tail(1), cb)\n",
    "            # flag for colorbar to avoid redrawing\n",
    "            cb = True\n",
    "\n",
    "            # Add footnotes\n",
    "            footnote_text = \"*U.S. Census dataset (predict Income): 45k rows, 10k cols\\nParameters: 5-fold cross-validation, \" + r'$\\alpha = \\{\\frac{i}{7},i=0\\ldots7\\}$' + \", \"\\\n",
    "   'full $\\lambda$-' + \"search\"\n",
    "            #pl.figtext(.05, -.04, footnote_text, fontsize = 14,)\n",
    "            pl.annotate(footnote_text, (0,0), (-30, -50), fontsize = 12,\n",
    "                        xycoords='axes fraction', textcoords='offset points', va='top')\n",
    "\n",
    "            #update the graphics\n",
    "            display.display(pl.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "            time.sleep(0.01)\n",
    "\n",
    "            #save the images\n",
    "            saveimage=0\n",
    "            if saveimage:\n",
    "                file_name = './images/glm_run_%04d.png' % (i,)\n",
    "                pl.savefig(file_name, dpi=200)\n",
    "            i=i+1\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "        except:\n",
    "            #print(\"Could not Create Frame\")\n",
    "            pass\n",
    "        \n",
    "def RunH2Oaiglm(arg):\n",
    "    intercept,standardize, lambda_min_ratio, nFolds, nAlphas, nLambdas, nGPUs = arg\n",
    "    # set solver cpu/gpu according to input args\n",
    "    if((nGPUs>0) and (h2oaiglm.ElasticNetSolverGPU is None)):\n",
    "        print(\"\\nGPU solver unavailable, using CPU solver\\n\")\n",
    "        nGPUs=0\n",
    "\n",
    "    nThreads = 1 if(nGPUs==0) else nGPUs # not required number of threads, but normal.  Bit more optimal to use 2 threads for CPU, but 1 thread per GPU is optimal.\n",
    "\n",
    "    print(\"Setting up Solver\")\n",
    "    os.system(\"rm -f rmse.txt ; touch rmse.txt ; rm -f varimp.txt ; touch varimp.txt\") ## for visualization\n",
    "    Solver = h2oaiglm.ElasticNetSolverGPU if(nGPUs>0) else h2oaiglm.ElasticNetSolverCPU\n",
    "    assert Solver != None, \"Couldn't instantiate ElasticNetSolver\"\n",
    "    enet = Solver(0, nThreads, nGPUs, 'c' if fortran else 'r', intercept, standardize, lambda_min_ratio, nLambdas, nFolds, nAlphas)\n",
    "\n",
    "    ## First, get backend pointers\n",
    "    t0 = time.time()\n",
    "    a,b,c,d,e = enet.upload_data(0, trainX, trainY, validX, validY, trainW)\n",
    "    t1 = time.time()\n",
    "    print(\"Time to ingest data: %r\" % (t1-t0))\n",
    "\n",
    "    ## Solve\n",
    "    print(\"Solving\")\n",
    "    t0 = time.time()\n",
    "    enet.fit(0, mTrain, n, mvalid, intercept, standardize, 0, a, b, c, d, e)\n",
    "    t1 = time.time()\n",
    "    print(\"Done Solving\")\n",
    "    print(\"Time to train H2O AI GLM: %r\" % (t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train 4000 Elastic Net Models (5-fold cross-validation, 8 $\\alpha$ values, 100 $\\lambda$ values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lambda_min_ratio=1E-9\n",
    "nFolds=5\n",
    "nAlphas=8\n",
    "nLambdas=100\n",
    "nGPUs=maxNGPUS  # select 0 for CPU, or 1 <= N <= maxNGPUs for GPU\n",
    "\n",
    "arg = intercept,standardize, lambda_min_ratio, nFolds, nAlphas, nLambdas, nGPUs \n",
    "futures = []\n",
    "Executor = ProcessPoolExecutor(max_workers=1)\n",
    "futures.append(Executor.submit(RunH2Oaiglm, arg)) ## run in separate process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RunAnimation(nGPUs)\n",
    "concurrent.futures.wait(futures)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
