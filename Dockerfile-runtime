ARG docker_name

FROM $docker_name

MAINTAINER H2o.ai <ops@h2o.ai>

# Refer https://github.com/moby/moby/issues/34129 for weird ARG behavior
ARG cudaversion
ARG PM=pip

ENV HOME=/root
ENV CUDA_HOME=/usr/local/cuda
ENV PATH=/usr/local/cuda/bin:$PATH
ENV CUDADIR=/usr/local/cuda/include/
ENV LD_LIBRARY_PATH=/usr/lib64:/usr/local/lib:$LD_LIBRARY_PATH

ENV MINICONDA_VERSION=4.4.10

# Setup gcc etc.
RUN yum install -y epel-release

RUN yum install -y gcc gcc-c++ libgcc libstdc++ libgomp glibc

RUN yum install -y \
    make \
    ncurses-devel \
	zlib-devel \
    epel-release \
    zeromq-devel \
	wget \
	blas-devel \
    openblas-devel \
    libpng-devel \
    freetype-devel \
	bzip2 && \
    wget https://repo.continuum.io/miniconda/Miniconda3-${MINICONDA_VERSION}-Linux-`arch`.sh && \
    bash Miniconda3-${MINICONDA_VERSION}-Linux-`arch`.sh -b -p /opt/h2oai/h2o4gpu/python
ENV PATH=/opt/h2oai/h2o4gpu/python/bin:$PATH

#
# PPC64 specific - certain libs/whl don't support PPC64LE
#

WORKDIR $HOME

# Arrow
RUN bash -c 'if [ `arch` = "ppc64le" ]; then \
	yum install -y git boost-devel cmake3 && \
	ln -s /usr/bin/cmake3 /usr/bin/cmake && \
	git clone https://github.com/apache/arrow.git && \
	cd $HOME/arrow/cpp && \
	git checkout tags/apache-arrow-0.8.0 && \
  	pip install numpy==1.14.5 cython && \
	cmake -DARROW_CXXFLAGS="-lutil" -DARROW_PYTHON=on && make -j && make install && \
	cd $HOME/arrow/python && \
	ARROW_HOME=/usr/local python setup.py install && \
	yum install -y libjpeg-devel; \
	fi'

# Pillow
ENV PILLOW_VERSION=4.2.1
RUN bash -c 'if [ `arch` = "ppc64le" ]; then \
	wget https://files.pythonhosted.org/packages/55/aa/f7f983fb72710a9daa4b3374b7c160091d3f94f5c09221f9336ade9027f3/Pillow-${PILLOW_VERSION}.tar.gz && \
	tar xvf Pillow-${PILLOW_VERSION}.tar.gz && \
	cd $HOME/Pillow-${PILLOW_VERSION} && \
	sed -i "s/'ppc64'/'ppc64le'/g" setup.py && \
	python setup.py install && \
	cd $HOME && \
	rm -rf Pillow-${PILLOW_VERSION}*; \
	fi'

WORKDIR /

# Add requirements
COPY src/interface_py/requirements_runtime.txt requirements.txt
COPY src/interface_py/requirements_runtime_demos.txt requirements_runtime_demos.txt
RUN bash -c 'if [ `arch` = "ppc64le" || $PM = "pip" ]; then \
    chmod a+rwx requirements*.txt && \
    pip install --no-cache-dir -r requirements.txt && \
    pip install --no-cache-dir -r requirements_runtime_demos.txt; \
    fi'

RUN bash -c 'if [ `arch` = "x86_64" && $PM = "conda" ]; then \
    conda create -n h2o4gpuenv -y -c h2oai -c conda-forge h2o4gpu$cudaversion && \
    source activate h2o4gpuenv && \
    conda install -y tornado==4.5.3; \
    fi'

RUN mkdir -p /etc/OpenCL/vendors && \
    echo "libnvidia-opencl.so.1" > /etc/OpenCL/vendors/nvidia.icd

RUN (localedef -v -c -i en_US -f UTF-8 en_US.UTF-8 || true)

ENV LANG en_US.UTF-8
ENV LANGUAGE en_US:en
ENV LD_LIBRARY_PATH_CUDA=$CUDA_HOME/lib64/:$CUDA_HOME/lib/:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64

# NCCL2 (License: https://docs.nvidia.com/deeplearning/sdk/nccl-sla/index.html)
RUN \
    bash -c 'if [ `arch` == "x86_64" ]; then \
    export CUDA_HOME=/usr/local/cuda ; if [ -d "$CUDA_HOME" ]; then \
    export CUDA_LIB=$CUDA_HOME/lib64 && \
    export CUDA_VERSION=`ls $CUDA_LIB/libcudart.so.* | head -1 | rev | cut -d "." -f -2 | rev` && \
    export CUDA_MAJOR=`echo $CUDA_VERSION | cut -d "." -f 1` && \
    export CUDA_MINOR=`echo $CUDA_VERSION | cut -d "." -f 2| sed 's/@//g'` && \
    export CUDA_SHORT=`echo $CUDA_VERSION | egrep -o '[0-9]\.[0-9]'` && \
    wget https://developer.download.nvidia.com/compute/redist/nccl/v2.2/nccl_2.2.13-1%2Bcuda${CUDA_SHORT}_`arch`.txz && \
    tar xf "nccl_2.2.13-1+cuda${CUDA_SHORT}_`arch`.txz" && \
    cp nccl_2.2.13-1+cuda${CUDA_SHORT}_`arch`/include/nccl.h /usr/include && \
    cp nccl_2.2.13-1+cuda${CUDA_SHORT}_`arch`/lib/* /usr/lib && \
    rm -f nccl_2.2.13-1+cuda${CUDA_SHORT}_`arch`.txz && \
    rm -r nccl_2.2.13-1+cuda${CUDA_SHORT}_`arch` ; \
    fi ; \
    fi'

# NCCL2 (License: https://docs.nvidia.com/deeplearning/sdk/nccl-sla/index.html)
RUN \
    bash -c 'if [ `arch` == "ppc64le" ]; then \
    export CUDA_HOME=/usr/local/cuda ; if [ -d "$CUDA_HOME" ]; then \
    export CUDA_LIB=$CUDA_HOME/lib64 && \
    export CUDA_VERSION=`ls $CUDA_LIB/libcudart.so.* | head -1 | rev | cut -d "." -f -2 | rev` && \
    export CUDA_MAJOR=`echo $CUDA_VERSION | cut -d "." -f 1` && \
    export CUDA_MINOR=`echo $CUDA_VERSION | cut -d "." -f 2| sed 's/@//g'` && \
    export CUDA_SHORT=`echo $CUDA_VERSION | egrep -o '[0-9]\.[0-9]'` && \
    wget https://developer.download.nvidia.com/compute/redist/nccl/v2.2/nccl_2.2.13-1%2Bcuda${CUDA_SHORT}_`arch`.tgz && \
    tar xzf "nccl_2.2.13-1+cuda${CUDA_SHORT}_`arch`.tgz" && \
    cp cuda/targets/`arch`-linux/include/nccl.h /usr/include/ && \
    cp cuda/targets/`arch`-linux/lib/* /usr/lib64/ && \
    rm -f nccl_2.2.13-1+cuda${CUDA_SHORT}_`arch`.tgz && \
    chmod -R a+rx /usr/include/ && \
    chmod -R a+rx /usr/lib64/ && \
    ldconfig && \
    rm -rf cuda ; \
    fi ; \
    fi' || true

# Add a canned jupyter notebook demo to the container
RUN \
  mkdir -p jupyter/demos
COPY examples/py/demos/H2O4GPU_Ridge.ipynb /jupyter/demos/H2O4GPU_Ridge.ipynb
COPY examples/py/demos/H2O4GPU_LinearRegression.ipynb /jupyter/demos/H2O4GPU_LinearRegression.ipynb
COPY examples/py/demos/H2O4GPU_GBM.ipynb /jupyter/demos/H2O4GPU_GBM.ipynb
COPY examples/py/demos/H2O4GPU_GLM.ipynb /jupyter/demos/H2O4GPU_GLM.ipynb
COPY examples/py/demos/H2O4GPU_Lasso.ipynb /jupyter/demos/H2O4GPU_Lasso.ipynb
COPY examples/py/demos/H2O4GPU_KMeans_Images.ipynb /jupyter/demos/H2O4GPU_KMeans_Images.ipynb
COPY examples/py/demos/H2O4GPU_KMeans_Quantization.ipynb /jupyter/demos/H2O4GPU_KMeans_Quantization.ipynb
COPY examples/py/demos/Multi-GPU-H2O-GLM-simple.ipynb /jupyter/demos/Multi-GPU-H2O-GLM-simple.ipynb
COPY examples/py/demos/H2O4GPU_TruncatedSVD.ipynb /jupyter/demos/H2O4GPU_TruncatedSVD.ipynb
COPY examples/py/demos/H2O4GPU_PCA.ipynb /jupyter/demos/H2O4GPU_PCA.ipynb
COPY examples/py/demos/H2O4GPU_Daal_LinearRegression.ipynb /jupyter/demos/H2O4GPU_Daal_LinearRegression.ipynb
COPY examples/py/demos/figures /jupyter/demos/figures
RUN \
  cd /jupyter/demos && \
  chmod -R a+rwx /jupyter && \
  mkdir /scikit_learn_data && \
  chmod -R a+rwx /scikit_learn_data && \
  mkdir -p /jupyter/scikit_learn_data/covertype && \
  chmod -R a+rwx /jupyter/scikit_learn_data/covertype && \
  mkdir -p /jupyter/scikit_learn_data/lfw_home && \
  chmod -R a+rwx /jupyter/scikit_learn_data/lfw_home && \
  if [ `arch` == "x86_64" ]; then source activate h2o4gpuenv; fi && \
  HOME=/jupyter jupyter notebook --generate-config && \
  sed -i "s/#c.NotebookApp.token = '<generated>'/c.NotebookApp.token = 'h2o'/" /jupyter/.jupyter/jupyter_notebook_config.py && \
  echo "c.NotebookApp.allow_remote_access = False" >> /jupyter/.jupyter/jupyter_notebook_config.py && \
  chmod -R a+rwx /jupyter/.jupyter

# Add shell wrapper
COPY scripts/run.sh /run.sh
RUN \
  chmod a+rwx run.sh

ARG h2o4gpu_VERSION
ARG h2o4gpu_COMMIT
ARG DOCKER_VERSION_TAG
LABEL \
h2o4gpu_commit="$h2o4gpu_COMMIT" \
docker_version_tag="$DOCKER_VERSION_TAG"

ENTRYPOINT ["./run.sh"]
EXPOSE 8888
