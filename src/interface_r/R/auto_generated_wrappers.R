# Note: This file is automatically generated by scripts/gen_wrappers.R. Please do not change. 

#' @export
h2o4gpu.random_forest_classifier <- function(
	n_estimators = 10L,
	criterion = "gini",
	max_depth = 3L,
	min_samples_split = 2L,
	min_samples_leaf = 1L,
	min_weight_fraction_leaf = 0.0,
	max_features = "auto",
	max_leaf_nodes = NULL,
	min_impurity_decrease = 0.0,
	min_impurity_split = NULL,
	bootstrap = TRUE,
	oob_score = FALSE,
	n_jobs = 1L,
	random_state = NULL,
	verbose = 0L,
	warm_start = FALSE,
	class_weight = NULL,
	subsample = 1.0,
	colsample_bytree = 1.0,
	num_parallel_tree = 1L,
	tree_method = "gpu_hist",
	n_gpus = -1L,
	predictor = "gpu_predictor",
	backend = "auto") {

  model <- h2o4gpu$RandomForestClassifier(
    n_estimators = as.integer(n_estimators),
    criterion = criterion,
    max_depth = as.integer(max_depth),
    min_samples_split = as.integer(min_samples_split),
    min_samples_leaf = as.integer(min_samples_leaf),
    min_weight_fraction_leaf = min_weight_fraction_leaf,
    max_features = max_features,
    max_leaf_nodes = max_leaf_nodes,
    min_impurity_decrease = min_impurity_decrease,
    min_impurity_split = min_impurity_split,
    bootstrap = bootstrap,
    oob_score = oob_score,
    n_jobs = as.integer(n_jobs),
    random_state = as_nullable_integer(random_state),
    verbose = as.integer(verbose),
    warm_start = warm_start,
    class_weight = class_weight,
    subsample = subsample,
    colsample_bytree = colsample_bytree,
    num_parallel_tree = as.integer(num_parallel_tree),
    tree_method = tree_method,
    n_gpus = as.integer(n_gpus),
    predictor = predictor,
    backend = backend
  )
  h2o4gpu_model(model, classifier)
}

#' @export
h2o4gpu.random_forest_regressor <- function(
	n_estimators = 10L,
	criterion = "mse",
	max_depth = 3L,
	min_samples_split = 2L,
	min_samples_leaf = 1L,
	min_weight_fraction_leaf = 0.0,
	max_features = "auto",
	max_leaf_nodes = NULL,
	min_impurity_decrease = 0.0,
	min_impurity_split = NULL,
	bootstrap = TRUE,
	oob_score = FALSE,
	n_jobs = 1L,
	random_state = NULL,
	verbose = 0L,
	warm_start = FALSE,
	subsample = 1.0,
	colsample_bytree = 1.0,
	num_parallel_tree = 1L,
	tree_method = "gpu_hist",
	n_gpus = -1L,
	predictor = "gpu_predictor",
	backend = "auto") {

  model <- h2o4gpu$RandomForestRegressor(
    n_estimators = as.integer(n_estimators),
    criterion = criterion,
    max_depth = as.integer(max_depth),
    min_samples_split = as.integer(min_samples_split),
    min_samples_leaf = as.integer(min_samples_leaf),
    min_weight_fraction_leaf = min_weight_fraction_leaf,
    max_features = max_features,
    max_leaf_nodes = max_leaf_nodes,
    min_impurity_decrease = min_impurity_decrease,
    min_impurity_split = min_impurity_split,
    bootstrap = bootstrap,
    oob_score = oob_score,
    n_jobs = as.integer(n_jobs),
    random_state = as_nullable_integer(random_state),
    verbose = as.integer(verbose),
    warm_start = warm_start,
    subsample = subsample,
    colsample_bytree = colsample_bytree,
    num_parallel_tree = as.integer(num_parallel_tree),
    tree_method = tree_method,
    n_gpus = as.integer(n_gpus),
    predictor = predictor,
    backend = backend
  )
  h2o4gpu_model(model, regressor)
}

#' @export
h2o4gpu.gradient_boosting_classifier <- function(
	loss = "deviance",
	learning_rate = 0.1,
	n_estimators = 100L,
	subsample = 1.0,
	criterion = "friedman_mse",
	min_samples_split = 2L,
	min_samples_leaf = 1L,
	min_weight_fraction_leaf = 0.0,
	max_depth = 3L,
	min_impurity_decrease = 0.0,
	min_impurity_split = NULL,
	init = NULL,
	random_state = NULL,
	max_features = "auto",
	verbose = 0L,
	max_leaf_nodes = NULL,
	warm_start = FALSE,
	presort = "auto",
	colsample_bytree = 1.0,
	num_parallel_tree = 1L,
	tree_method = "gpu_hist",
	n_gpus = -1L,
	predictor = "gpu_predictor",
	backend = "auto") {

  model <- h2o4gpu$GradientBoostingClassifier(
    loss = loss,
    learning_rate = learning_rate,
    n_estimators = as.integer(n_estimators),
    subsample = subsample,
    criterion = criterion,
    min_samples_split = as.integer(min_samples_split),
    min_samples_leaf = as.integer(min_samples_leaf),
    min_weight_fraction_leaf = min_weight_fraction_leaf,
    max_depth = as.integer(max_depth),
    min_impurity_decrease = min_impurity_decrease,
    min_impurity_split = min_impurity_split,
    init = init,
    random_state = as_nullable_integer(random_state),
    max_features = max_features,
    verbose = as.integer(verbose),
    max_leaf_nodes = max_leaf_nodes,
    warm_start = warm_start,
    presort = presort,
    colsample_bytree = colsample_bytree,
    num_parallel_tree = as.integer(num_parallel_tree),
    tree_method = tree_method,
    n_gpus = as.integer(n_gpus),
    predictor = predictor,
    backend = backend
  )
  h2o4gpu_model(model, classifier)
}

#' @export
h2o4gpu.gradient_boosting_regressor <- function(
	loss = "ls",
	learning_rate = 0.1,
	n_estimators = 100L,
	subsample = 1.0,
	criterion = "friedman_mse",
	min_samples_split = 2L,
	min_samples_leaf = 1L,
	min_weight_fraction_leaf = 0.0,
	max_depth = 3L,
	min_impurity_decrease = 0.0,
	min_impurity_split = NULL,
	init = NULL,
	random_state = NULL,
	max_features = "auto",
	alpha = 0.9,
	verbose = 0L,
	max_leaf_nodes = NULL,
	warm_start = FALSE,
	presort = "auto",
	colsample_bytree = 1.0,
	num_parallel_tree = 1L,
	tree_method = "gpu_hist",
	n_gpus = -1L,
	predictor = "gpu_predictor",
	backend = "auto") {

  model <- h2o4gpu$GradientBoostingRegressor(
    loss = loss,
    learning_rate = learning_rate,
    n_estimators = as.integer(n_estimators),
    subsample = subsample,
    criterion = criterion,
    min_samples_split = as.integer(min_samples_split),
    min_samples_leaf = as.integer(min_samples_leaf),
    min_weight_fraction_leaf = min_weight_fraction_leaf,
    max_depth = as.integer(max_depth),
    min_impurity_decrease = min_impurity_decrease,
    min_impurity_split = min_impurity_split,
    init = init,
    random_state = as_nullable_integer(random_state),
    max_features = max_features,
    alpha = alpha,
    verbose = as.integer(verbose),
    max_leaf_nodes = max_leaf_nodes,
    warm_start = warm_start,
    presort = presort,
    colsample_bytree = colsample_bytree,
    num_parallel_tree = as.integer(num_parallel_tree),
    tree_method = tree_method,
    n_gpus = as.integer(n_gpus),
    predictor = predictor,
    backend = backend
  )
  h2o4gpu_model(model, regressor)
}

#' @export
h2o4gpu.linear_regressor <- function(
	fit_intercept = TRUE,
	normalize = FALSE,
	copy_X = TRUE,
	n_jobs = 1L,
	n_gpus = -1L,
	tol = 0.0001,
	glm_stop_early = TRUE,
	glm_stop_early_error_fraction = 1.0,
	verbose = FALSE,
	backend = "auto") {

  model <- h2o4gpu$LinearRegression(
    fit_intercept = fit_intercept,
    normalize = normalize,
    copy_X = copy_X,
    n_jobs = as.integer(n_jobs),
    n_gpus = as.integer(n_gpus),
    tol = tol,
    glm_stop_early = glm_stop_early,
    glm_stop_early_error_fraction = glm_stop_early_error_fraction,
    verbose = verbose,
    backend = backend
  )
  h2o4gpu_model(model, regressor)
}

#' @export
h2o4gpu.logistic_regressor <- function(
	penalty = "l2",
	dual = FALSE,
	tol = 0.01,
	C = 1.0,
	fit_intercept = TRUE,
	intercept_scaling = 1.0,
	class_weight = NULL,
	random_state = NULL,
	solver = "liblinear",
	max_iter = 5000L,
	multi_class = "ovr",
	verbose = 0L,
	warm_start = FALSE,
	n_jobs = 1L,
	n_gpus = -1L,
	glm_stop_early = TRUE,
	glm_stop_early_error_fraction = 1.0,
	backend = "auto") {

  model <- h2o4gpu$LogisticRegression(
    penalty = penalty,
    dual = dual,
    tol = tol,
    C = C,
    fit_intercept = fit_intercept,
    intercept_scaling = intercept_scaling,
    class_weight = class_weight,
    random_state = as_nullable_integer(random_state),
    solver = solver,
    max_iter = as.integer(max_iter),
    multi_class = multi_class,
    verbose = as.integer(verbose),
    warm_start = warm_start,
    n_jobs = as.integer(n_jobs),
    n_gpus = as.integer(n_gpus),
    glm_stop_early = glm_stop_early,
    glm_stop_early_error_fraction = glm_stop_early_error_fraction,
    backend = backend
  )
  h2o4gpu_model(model, classifier)
}

#' @export
h2o4gpu.lasso_regressor <- function(
	alpha = 1.0,
	fit_intercept = TRUE,
	normalize = FALSE,
	precompute = FALSE,
	copy_X = TRUE,
	max_iter = 5000L,
	tol = 0.01,
	warm_start = FALSE,
	positive = FALSE,
	random_state = NULL,
	selection = "cyclic",
	n_gpus = -1L,
	glm_stop_early = TRUE,
	glm_stop_early_error_fraction = 1.0,
	verbose = FALSE,
	backend = "auto") {

  model <- h2o4gpu$Lasso(
    alpha = alpha,
    fit_intercept = fit_intercept,
    normalize = normalize,
    precompute = precompute,
    copy_X = copy_X,
    max_iter = as.integer(max_iter),
    tol = tol,
    warm_start = warm_start,
    positive = positive,
    random_state = as_nullable_integer(random_state),
    selection = selection,
    n_gpus = as.integer(n_gpus),
    glm_stop_early = glm_stop_early,
    glm_stop_early_error_fraction = glm_stop_early_error_fraction,
    verbose = verbose,
    backend = backend
  )
  h2o4gpu_model(model, regressor)
}

#' @export
h2o4gpu.ridge_regressor <- function(
	alpha = 1.0,
	fit_intercept = TRUE,
	normalize = FALSE,
	copy_X = TRUE,
	max_iter = 5000L,
	tol = 0.01,
	solver = "auto",
	random_state = NULL,
	n_gpus = -1L,
	glm_stop_early = TRUE,
	glm_stop_early_error_fraction = 1.0,
	verbose = FALSE,
	backend = "auto") {

  model <- h2o4gpu$Ridge(
    alpha = alpha,
    fit_intercept = fit_intercept,
    normalize = normalize,
    copy_X = copy_X,
    max_iter = as.integer(max_iter),
    tol = tol,
    solver = solver,
    random_state = as_nullable_integer(random_state),
    n_gpus = as.integer(n_gpus),
    glm_stop_early = glm_stop_early,
    glm_stop_early_error_fraction = glm_stop_early_error_fraction,
    verbose = verbose,
    backend = backend
  )
  h2o4gpu_model(model, regressor)
}

#' @export
h2o4gpu.elastic_net_regressor <- function(
	alpha = 1.0,
	l1_ratio = 0.5,
	fit_intercept = TRUE,
	normalize = FALSE,
	precompute = FALSE,
	max_iter = 5000L,
	copy_X = TRUE,
	tol = 0.01,
	warm_start = FALSE,
	positive = FALSE,
	random_state = NULL,
	selection = "cyclic",
	n_gpus = -1L,
	lambda_stop_early = TRUE,
	glm_stop_early = TRUE,
	glm_stop_early_error_fraction = 1.0,
	verbose = FALSE,
	backend = "auto") {

  model <- h2o4gpu$ElasticNet(
    alpha = alpha,
    l1_ratio = l1_ratio,
    fit_intercept = fit_intercept,
    normalize = normalize,
    precompute = precompute,
    max_iter = as.integer(max_iter),
    copy_X = copy_X,
    tol = tol,
    warm_start = warm_start,
    positive = positive,
    random_state = as_nullable_integer(random_state),
    selection = selection,
    n_gpus = as.integer(n_gpus),
    lambda_stop_early = lambda_stop_early,
    glm_stop_early = glm_stop_early,
    glm_stop_early_error_fraction = glm_stop_early_error_fraction,
    verbose = verbose,
    backend = backend
  )
  h2o4gpu_model(model, regressor)
}

#' @export
h2o4gpu.kmeans <- function(
	n_clusters = 8L,
	init = "k-means++",
	n_init = 1L,
	max_iter = 300L,
	tol = 0.0001,
	precompute_distances = "auto",
	verbose = 0L,
	random_state = NULL,
	copy_x = TRUE,
	n_jobs = 1L,
	algorithm = "auto",
	gpu_id = 0L,
	n_gpus = -1L,
	do_checks = 1L,
	backend = "auto") {

  model <- h2o4gpu$KMeans(
    n_clusters = as.integer(n_clusters),
    init = init,
    n_init = as.integer(n_init),
    max_iter = as.integer(max_iter),
    tol = tol,
    precompute_distances = precompute_distances,
    verbose = as.integer(verbose),
    random_state = as_nullable_integer(random_state),
    copy_x = copy_x,
    n_jobs = as.integer(n_jobs),
    algorithm = algorithm,
    gpu_id = as.integer(gpu_id),
    n_gpus = as.integer(n_gpus),
    do_checks = as.integer(do_checks),
    backend = backend
  )
  h2o4gpu_model(model, NULL)
}

#' @export
h2o4gpu.pca <- function(
	n_components = 2L,
	copy = TRUE,
	whiten = FALSE,
	svd_solver = "arpack",
	tol = 0.0,
	iterated_power = "auto",
	random_state = NULL,
	verbose = FALSE,
	backend = "auto") {

  model <- h2o4gpu$PCA(
    n_components = as.integer(n_components),
    copy = copy,
    whiten = whiten,
    svd_solver = svd_solver,
    tol = tol,
    iterated_power = iterated_power,
    random_state = as_nullable_integer(random_state),
    verbose = verbose,
    backend = backend
  )
  h2o4gpu_model(model, NULL)
}

#' @export
h2o4gpu.truncated_svd <- function(
	n_components = 2L,
	algorithm = "arpack",
	n_iter = 5L,
	random_state = NULL,
	tol = 0.0,
	verbose = FALSE,
	backend = "auto") {

  model <- h2o4gpu$TruncatedSVD(
    n_components = as.integer(n_components),
    algorithm = algorithm,
    n_iter = as.integer(n_iter),
    random_state = as_nullable_integer(random_state),
    tol = tol,
    verbose = verbose,
    backend = backend
  )
  h2o4gpu_model(model, NULL)
}

